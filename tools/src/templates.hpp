// Embedded templates for code generation.
//
// These string constants define the entire output structure of the generated
// test implementation and its building blocks. They are consumed by the
// emitter (emit.cpp) and rendered via fmt::format (partials) or plain
// placeholder replacement (main). Keeping templates in one header makes them
// easy to locate, review, and change.
//
// Placeholders and where they apply:
// - Main file (test_impl):
//     {{INCLUDE_SOURCES}}, {{FORWARD_DECLS}}, {{TRAIT_DECLS}},
//     {{WRAPPER_IMPLS}}, {{CASE_INITS}}, {{GROUP_RUNNERS}},
//     {{RUN_GROUPS}}, {{ENTRY_FUNCTION}}
//   The emitter uses simple string replacement for these.
// - Partials (formatted with fmt::format):
//   wrapper_free:     {w}, {fn}
//   wrapper_free_fixtures: {w}, {fn}, {decls}, {setup}, {teardown}, {call}
//   wrapper_ephemeral:{w}, {fixture}, {method}
//   wrapper_stateful: {w}, {fixture}, {method}
//   case_entry:       {name}, {wrapper}, {file}, {line}, {tags}, {reqs},
//                     {skip_reason}, {should_skip}, {fixture}, {lifetime}, {suite}
//   group_runner_*:   {gid}, {fixture}, {count}, {idxs}
//   array_decl_*:     {name}; or {count}, {name}, {body}
//   forward_decl_*:   {name}; or {scope}, {lines}
//
// IMPORTANT: Partials are fed into fmt::format, so any literal braces that
// must appear in the generated C++ need to be doubled here (e.g. function
// bodies, initializer lists, random_device{{}}).

#pragma once

#include <string_view>

namespace gentest::codegen::tpl {

inline constexpr std::string_view test_impl = R"CPP(// This file is auto-generated by gentest_codegen.
// Do not edit manually.

#include <array>
#include <exception>
#include <string>
#include <fmt/core.h>
#include <fmt/color.h>
#include <cstdlib>
#include <random>
#include <algorithm>
#include <type_traits>
#include <span>
#include <string_view>
#include <vector>
#include <memory>
#include <chrono>
#include <fstream>
#include <map>
#include <filesystem>
#include <cmath>
#ifdef GENTEST_USE_BOOST_JSON
#  include <boost/json.hpp>
#endif
#ifdef GENTEST_USE_BOOST_UUID
#  include <boost/uuid/uuid.hpp>
#  include <boost/uuid/uuid_generators.hpp>
#  include <boost/uuid/uuid_io.hpp>
#endif

#include "gentest/runner.h"
#include "gentest/fixture.h"

// Include test sources so fixture types are visible for wrappers
{{INCLUDE_SOURCES}}

// Include generated mock implementations (requires sources/types to be visible)
{{INCLUDE_MOCK_IMPL}}

{{FORWARD_DECLS}}
{{ACCESSOR_DECLS}}
namespace {

{{TRAIT_DECLS}}

// Per-case invocation wrappers. All wrappers use a uniform signature
//   void(void* ctx)
// Free tests ignore ctx; ephemeral fixtures construct a new instance per call;
// shared fixtures expect ctx to point to the shared fixture instance.
template <typename T>
inline void gentest_maybe_setup(T& t) {
    if constexpr (std::is_base_of_v<gentest::FixtureSetup, T>) t.setUp();
}

template <typename T>
inline void gentest_maybe_teardown(T& t) {
    if constexpr (std::is_base_of_v<gentest::FixtureTearDown, T>) t.tearDown();
}
{{WRAPPER_IMPLS}}

enum class FixtureLifetime {
    None,
    MemberEphemeral,
    MemberSuite,
    MemberGlobal,
};

using FixtureAccessor = void* (*)(std::string_view);

struct Case {
    std::string_view                  name;
    void (*fn)(void*);
    std::string_view                  file;
    unsigned                          line;
    bool                              is_benchmark;
    bool                              is_jitter;
    std::span<const std::string_view> tags;
    std::span<const std::string_view> requirements;
    std::string_view                  skip_reason;
    bool                              should_skip;
    std::string_view                  fixture;        // empty for free tests
    FixtureLifetime                   fixture_lifetime;
    std::string_view                  suite;
    FixtureAccessor                   acquire_fixture;
};

constexpr std::array<Case, {{CASE_COUNT}}> kCases = {
{{CASE_INITS}}
};
} // namespace

namespace {
bool wants_list(std::span<const char*> args) {
    for (const auto* arg : args) {
        if (arg != nullptr && std::string_view(arg) == "--list") {
            return true;
        }
    }
    return false;
}

bool wants_shuffle(std::span<const char*> args) {
    for (const auto* arg : args) {
        if (arg != nullptr && std::string_view(arg) == "--shuffle-fixtures") {
            return true;
        }
    }
    return false;
}

std::uint64_t parse_seed(std::span<const char*> args) {
    for (std::size_t i = 0; i + 1 < args.size(); ++i) {
        if (args[i] != nullptr && std::string_view(args[i]) == "--seed") {
            if (args[i + 1]) {
                std::uint64_t v = 0;
                for (const char ch : std::string_view(args[i + 1])) {
                    if (ch < '0' || ch > '9') { v = 0; break; }
                    v = v * 10 + static_cast<std::uint64_t>(ch - '0');
                }
                if (v != 0) return v;
            }
        }
    }
    return 0;
}
} // namespace

namespace {
bool wants_help(std::span<const char*> args) {
    for (const auto* arg : args) if (arg && std::string_view(arg) == "--help") return true;
    return false;
}

bool wants_list_tests(std::span<const char*> args) {
    for (const auto* arg : args) if (arg && std::string_view(arg) == "--list-tests") return true;
    return false;
}


const char* get_arg_value(std::span<const char*> args, std::string_view prefix) {
    for (const auto* arg : args) {
        if (!arg) continue;
        std::string_view s(arg);
        if (s.rfind(prefix, 0) == 0) return arg + prefix.size();
    }
    return nullptr;
}

bool wants_fail_fast(std::span<const char*> args) {
    for (const auto* arg : args) if (arg && std::string_view(arg) == "--fail-fast") return true;
    return false;
}

std::size_t parse_repeat(std::span<const char*> args) {
    const char* v = get_arg_value(args, "--repeat=");
    if (!v) return 1;
    std::size_t n = 0;
    for (const char ch : std::string_view(v)) {
        if (ch < '0' || ch > '9') { n = 0; break; }
        n = n * 10 + static_cast<std::size_t>(ch - '0');
        if (n > 1000000) { n = 1000000; break; }
    }
    return n == 0 ? 1 : n;
}

bool wildcard_match(std::string_view text, std::string_view pattern) {
    std::size_t ti = 0, pi = 0, star = std::string_view::npos, mark = 0;
    while (ti < text.size()) {
        if (pi < pattern.size() && (pattern[pi] == '?' || pattern[pi] == text[ti])) { ++ti; ++pi; continue; }
        if (pi < pattern.size() && pattern[pi] == '*') { star = pi++; mark = ti; continue; }
        if (star != std::string_view::npos) { pi = star + 1; ti = ++mark; continue; }
        return false;
    }
    while (pi < pattern.size() && pattern[pi] == '*') ++pi;
    return pi == pattern.size();
}

std::string join_span(std::span<const std::string_view> items, char sep) {
    std::string out;
    for (std::size_t i = 0; i < items.size(); ++i) {
        if (i != 0) out.push_back(sep);
        out.append(items[i]);
    }
    return out;
}
// Color handling
bool g_color_output = true;
bool wants_no_color(std::span<const char*> args) {
    for (const auto* arg : args) if (arg && std::string_view(arg) == "--no-color") return true;
    return false;
}
bool env_no_color() {
    const char* a = std::getenv("NO_COLOR");
    if (a && *a) return true;
    a = std::getenv("GENTEST_NO_COLOR");
    if (a && *a) return true;
    return false;
}
bool use_color(std::span<const char*> args) { return !wants_no_color(args) && !env_no_color(); }
// GitHub annotations
bool g_github_annotations = false;
bool wants_github_annotations(std::span<const char*> args) {
    for (const auto* arg : args) if (arg && std::string_view(arg) == "--github-annotations") return true;
    return false;
}
bool env_github_actions() {
    const char* a = std::getenv("GITHUB_ACTIONS");
    if (a && *a) return true;
    return false;
}
static inline std::string gha_escape(std::string_view s) {
    std::string out;
    out.reserve(s.size());
    for (char ch : s) {
        switch (ch) {
        case '%': out += "%25"; break;
        case '\r': out += "%0D"; break;
        case '\n': out += "%0A"; break;
        default: out.push_back(ch); break;
        }
    }
    return out;
}
} // namespace

namespace {
// Benchmark CLI helpers
const char* get_arg_value_sv(std::span<const char*> args, std::string_view prefix) {
    for (const auto* arg : args) {
        if (!arg) continue;
        std::string_view s(arg);
        if (s.rfind(prefix, 0) == 0) return arg + prefix.size();
    }
    return nullptr;
}
bool wants_list_benches(std::span<const char*> args) {
    for (const auto* a : args) if (a && std::string_view(a) == "--list-benches") return true; return false;
}
const char* wants_run_bench(std::span<const char*> args) { return get_arg_value_sv(args, "--run-bench="); }
const char* wants_bench_filter(std::span<const char*> args) { return get_arg_value_sv(args, "--bench-filter="); }

// bench config
static inline std::size_t parse_szt(const char* s, std::size_t defv) {
    if (!s) return defv; std::size_t n = 0; for (char ch : std::string_view(s)) { if (ch < '0' || ch > '9') return defv; n = n*10 + (ch-'0'); if (n > (std::size_t(1)<<62)) return defv; } return n;
}
static inline double parse_double(const char* s, double defv) {
    if (!s) return defv; try { return std::stod(std::string(s)); } catch (...) { return defv; }
}
struct BenchConfig {
    // durations in seconds
    double min_epoch_time_s = 0.01; // 10ms
    double max_total_time_s = 1.0;  // per benchmark
    std::size_t warmup_epochs = 1;
    std::size_t measure_epochs = 12;
};
BenchConfig parse_bench_config(std::span<const char*> args) {
    BenchConfig cfg;
    cfg.min_epoch_time_s = parse_double(get_arg_value_sv(args, "--bench-min-epoch-time-s="), cfg.min_epoch_time_s);
    cfg.max_total_time_s = parse_double(get_arg_value_sv(args, "--bench-max-total-time-s="), cfg.max_total_time_s);
    cfg.warmup_epochs = parse_szt(get_arg_value_sv(args, "--bench-warmup="), cfg.warmup_epochs);
    cfg.measure_epochs = parse_szt(get_arg_value_sv(args, "--bench-epochs="), cfg.measure_epochs);
    if (cfg.measure_epochs == 0) cfg.measure_epochs = 1;
    return cfg;
}

struct BenchResult { std::size_t epochs = 0; std::size_t iters_per_epoch = 0; double best_ns = 0; double median_ns = 0; double mean_ns = 0; };

struct EpochResult { double time_s = 0.0; std::size_t iterations_done = 0; std::size_t expect_fails = 0; bool had_assert = false; };

static inline EpochResult run_epoch_with_context(const Case& c, void* ctx, std::size_t iters) {
    using clock = std::chrono::steady_clock;
    EpochResult er{};
    auto ctxinfo = std::make_shared<gentest::detail::TestContextInfo>();
    ctxinfo->display_name = std::string(c.name);
    ctxinfo->active = true;
    gentest::detail::set_current_test(ctxinfo);
    auto start = clock::now();
    for (std::size_t i = 0; i < iters; ++i) {
        try {
            c.fn(ctx);
        } catch (const gentest::assertion&) {
            er.had_assert = true;
            break;
        } catch (const gentest::failure&) {
            // Counted as failed EXPECT-like condition but continue
        } catch (const std::exception&) {
            // Treat as failure but continue
        } catch (...) {
            // Unknown: continue
        }
        er.iterations_done = i + 1;
    }
    auto end = clock::now();
    ctxinfo->active = false;
    gentest::detail::set_current_test(nullptr);
    er.expect_fails = 0;
    for (char k : ctxinfo->event_kinds) if (k == 'F') ++er.expect_fails;
    er.time_s = std::chrono::duration<double>(end - start).count();
    return er;
}

BenchResult run_benchmark_case(const Case& bench, void* ctx, const BenchConfig& cfg, bool& had_failures_out) {
    using clock = std::chrono::steady_clock;
    BenchResult br;
    // Calibrate iterations per epoch to meet min epoch time
    std::size_t iters = 1;
    auto run_iters = [&](std::size_t n) { EpochResult er = run_epoch_with_context(bench, ctx, n); if (er.expect_fails > 0 || er.had_assert) had_failures_out = true; return er.time_s; };
    // Warmup calibration
    while (run_iters(iters) < cfg.min_epoch_time_s) {
        iters *= 2; if (iters == 0) { iters = 1; break; }
        if (iters > (std::size_t(1) << 30)) break;
    }
    // Warmup epochs
    for (std::size_t i = 0; i < cfg.warmup_epochs; ++i) (void)run_iters(iters);
    std::vector<double> ns_per_iter;
    ns_per_iter.reserve(cfg.measure_epochs);
    double total_time_s = 0.0;
    for (std::size_t e = 0; e < cfg.measure_epochs; ++e) {
        double t = run_iters(iters);
        total_time_s += t;
        double ns_iter = (t * 1e9) / static_cast<double>(iters);
        ns_per_iter.push_back(ns_iter);
        if (total_time_s >= cfg.max_total_time_s) { br.epochs = e + 1; break; }
    }
    if (br.epochs == 0) br.epochs = ns_per_iter.size();
    if (ns_per_iter.empty()) { br.iters_per_epoch = iters; br.best_ns = br.median_ns = br.mean_ns = 0.0; return br; }
    std::vector<double> sorted = ns_per_iter; std::sort(sorted.begin(), sorted.end());
    br.iters_per_epoch = iters;
    br.best_ns = sorted.front();
    br.median_ns = sorted[sorted.size()/2];
    double sum = 0.0; for (double v : ns_per_iter) sum += v; br.mean_ns = sum / static_cast<double>(ns_per_iter.size());
    return br;
}

int handle_bench_cli(std::span<const char*> args) {
    if (wants_list_benches(args)) {
        std::size_t count = 0;
        for (const auto& c : kCases) if (c.is_benchmark) { fmt::print("{}:{} {}\n", c.file, c.line, c.name); ++count; }
        fmt::print("Found {} benchmark case(s).\n", count);
        return 0;
    }
    const char* run_exact = wants_run_bench(args);
    const char* filter_pat = wants_bench_filter(args);
    if (!run_exact && !filter_pat) return -1; // not a bench run request
    std::vector<std::size_t> sel;
    if (run_exact) {
        for (std::size_t i = 0; i < kCases.size(); ++i) if (kCases[i].is_benchmark && std::string_view(kCases[i].name) == run_exact) { sel.push_back(i); break; }
        if (sel.empty()) { fmt::print(stderr, "Benchmark not found: {}\n", run_exact); return 1; }
    } else {
        for (std::size_t i = 0; i < kCases.size(); ++i) if (kCases[i].is_benchmark && wildcard_match(kCases[i].name, filter_pat)) sel.push_back(i);
        if (sel.empty()) { fmt::print("Matched 0 benchmark(s).\n"); return 0; }
    }
    BenchConfig cfg = parse_bench_config(args);
    const bool print_table = [] (std::span<const char*> a){ for (auto* p: a) if (p && std::string_view(p) == "--bench-table") return true; return false; }(args);
    struct Row{ std::string name; std::size_t iters; std::size_t epochs; double best; double median; double mean; double ops_s; };
    std::vector<Row> rows;
    // Group by fixture and lifetime similar to tests
    bool had_failures = false;
    for (auto i : sel) {
        const auto& c = kCases[i];
        void* ctx = nullptr;
        switch (c.fixture_lifetime) {
        case FixtureLifetime::MemberSuite:
        case FixtureLifetime::MemberGlobal:
            if (c.acquire_fixture) ctx = c.acquire_fixture(c.suite);
            break;
        case FixtureLifetime::MemberEphemeral:
        case FixtureLifetime::None:
        default: ctx = nullptr; break;
        }
        try {
            fmt::print("[ BENCH ] {}\n", c.name);
            bool br_fail = false;
            auto result = run_benchmark_case(c, ctx, cfg, br_fail);
            had_failures = had_failures || br_fail;
            const double ops_per_s = result.mean_ns > 0.0 ? (1e9 / result.mean_ns) : 0.0;
            fmt::print("  epochs: {}  iters/epoch: {}\n", result.epochs, result.iters_per_epoch);
            fmt::print("  ns/op  best: {:.2f}  median: {:.2f}  mean: {:.2f}  ({:.2f} ops/s)\n", result.best_ns, result.median_ns, result.mean_ns, ops_per_s);
            if (print_table) rows.push_back(Row{std::string(c.name), result.iters_per_epoch, result.epochs, result.best_ns, result.median_ns, result.mean_ns, ops_per_s});
        } catch (const std::exception& e) {
            fmt::print(stderr, "[ FAIL ] {} :: exception: {}\n", c.name, e.what());
            return 1;
        } catch (...) {
            fmt::print(stderr, "[ FAIL ] {} :: unknown exception\n", c.name);
            return 1;
        }
    }
    if (print_table) {
        fmt::print("\nSummary (benchmarks)\n");
        fmt::print("{:>8}  {:<50}  {:>12}  {:>10}  {:>10}  {:>10}  {:>12}\n", "epochs", "name", "iters/epoch", "best(ns)", "median(ns)", "mean(ns)", "ops/s");
        for (const auto& r : rows) {
            fmt::print("{:>8}  {:<50}  {:>12}  {:>10.2f}  {:>10.2f}  {:>10.2f}  {:>12.2f}\n", r.epochs, r.name, r.iters, r.best, r.median, r.mean, r.ops_s);
        }
    }
    if (print_table) {
        fmt::print("\nSummary (benchmarks)\n");
        fmt::print("{:>8}  {:<50}  {:>12}  {:>10}  {:>10}  {:>10}  {:>12}\n", "epochs", "name", "iters/epoch", "best(ns)", "median(ns)", "mean(ns)", "ops/s");
        for (const auto& r : rows) {
            fmt::print("{:>8}  {:<50}  {:>12}  {:>10.2f}  {:>10.2f}  {:>10.2f}  {:>12.2f}\n", r.epochs, r.name, r.iters, r.best, r.median, r.mean, r.ops_s);
        }
    }
    return had_failures ? 1 : 0;
}
} // namespace

namespace {
// Jitter benchmark CLI helpers
bool wants_list_jitters(std::span<const char*> args) { for (const auto* a : args) if (a && std::string_view(a) == "--list-jitters") return true; return false; }
const char* wants_run_jitter(std::span<const char*> args) { return get_arg_value_sv(args, "--run-jitter="); }
const char* wants_jitter_filter(std::span<const char*> args) { return get_arg_value_sv(args, "--jitter-filter="); }
std::size_t parse_bins(std::span<const char*> args) { return parse_szt(get_arg_value_sv(args, "--jitter-bins="), 10); }

struct JitterStats { double mean_ns = 0.0; double variance_ns2 = 0.0; double stddev_ns = 0.0; double min_ns = 0.0; double max_ns = 0.0; };
static inline JitterStats compute_stats(const std::vector<double>& v) {
    JitterStats js{}; if (v.empty()) return js; double sum=0.0; js.min_ns=v[0]; js.max_ns=v[0]; for (double x : v){sum+=x; if(x<js.min_ns)js.min_ns=x; if(x>js.max_ns)js.max_ns=x;} js.mean_ns=sum/static_cast<double>(v.size()); double var=0.0; for (double x: v){double d=x-js.mean_ns; var+=d*d;} var/= static_cast<double>(v.size()); js.variance_ns2=var; js.stddev_ns=std::sqrt(var); return js; }

static inline void print_histogram(const std::vector<double>& v, std::size_t bins) {
    if (v.empty() || bins==0) return;
    double minv=*std::min_element(v.begin(), v.end());
    double maxv=*std::max_element(v.begin(), v.end());
    fmt::print("  histogram (ns/op):\n");
    fmt::print("  {:>22}  {:>8}  {:>8}  {}\n", "range", "count", "percent", "bar");
    if (maxv<=minv) {
        std::string barstr(40, '#');
        fmt::print("  [{:.2f},{:.2f}] ns/op  {:>8}  {:>7.1f}%  {}\n", minv, maxv, v.size(), 100.0, barstr);
        return;
    }
    double width=(maxv-minv)/static_cast<double>(bins);
    std::vector<std::size_t> counts(bins, 0);
    for (double x : v){ std::size_t idx = static_cast<std::size_t>((x-minv)/width); if (idx>=bins) idx=bins-1; counts[idx]++; }
    std::size_t maxc=*std::max_element(counts.begin(), counts.end());
    for (std::size_t i=0;i<bins;++i){
        double lo=minv+width*static_cast<double>(i);
        double hi=(i+1==bins)?maxv:(lo+width);
        double pct = (v.empty()?0.0:(100.0*static_cast<double>(counts[i])/static_cast<double>(v.size())));
        std::size_t bar = maxc? static_cast<std::size_t>(40.0*static_cast<double>(counts[i])/static_cast<double>(maxc)) : 0;
        std::string barstr(bar, '#');
        fmt::print("  [{:.2f},{:.2f}) ns/op  {:>8}  {:>7.1f}%  {}\n", lo, hi, counts[i], pct, barstr);
    }
}

int handle_jitter_cli(std::span<const char*> args) {
    if (wants_list_jitters(args)) { std::size_t count=0; for (const auto& c : kCases) if (c.is_jitter) { fmt::print("{}:{} {}\n", c.file, c.line, c.name); ++count; } fmt::print("Found {} jitter benchmark case(s).\n", count); return 0; }
    const char* run_exact = wants_run_jitter(args); const char* filter_pat = wants_jitter_filter(args); if (!run_exact && !filter_pat) return -1;
    std::vector<std::size_t> sel; if (run_exact) { for (std::size_t i=0;i<kCases.size();++i) if (kCases[i].is_jitter && std::string_view(kCases[i].name)==run_exact) { sel.push_back(i); break; } if (sel.empty()) { fmt::print(stderr, "Jitter benchmark not found: {}\n", run_exact); return 1; } } else { for (std::size_t i=0;i<kCases.size();++i) if (kCases[i].is_jitter && wildcard_match(kCases[i].name, filter_pat)) sel.push_back(i); if (sel.empty()) { fmt::print("Matched 0 jitter benchmark(s).\n"); return 0; } }
    BenchConfig cfg = parse_bench_config(args); std::size_t bins = parse_bins(args);
    for (auto i : sel) {
        const auto& c = kCases[i]; void* ctx=nullptr; switch (c.fixture_lifetime) { case FixtureLifetime::MemberSuite: case FixtureLifetime::MemberGlobal: if (c.acquire_fixture) ctx=c.acquire_fixture(c.suite); break; case FixtureLifetime::MemberEphemeral: case FixtureLifetime::None: default: ctx=nullptr; break; }
        try {
            fmt::print("[ JITTER ] {}\n", c.name);
            auto run_iters = [&](std::size_t n){ return run_epoch_with_context(c, ctx, n); };
            std::size_t iters=1; while (run_iters(iters).time_s < cfg.min_epoch_time_s) { iters*=2; if (iters==0 || iters>(std::size_t(1)<<30)) break; }
            for (std::size_t w=0; w<cfg.warmup_epochs; ++w) (void)run_iters(iters);
            std::vector<double> ns_per_iter; ns_per_iter.reserve(cfg.measure_epochs);
            std::size_t failed_expect_epochs = 0; bool killed_by_assert = false; double total=0.0;
            for (std::size_t e=0;e<cfg.measure_epochs;++e){
                EpochResult er = run_iters(iters);
                total += er.time_s;
                if (er.had_assert) { killed_by_assert = true; break; }
                if (er.expect_fails > 0 || er.iterations_done == 0) { ++failed_expect_epochs; if (total >= cfg.max_total_time_s) break; else continue; }
                ns_per_iter.push_back((er.time_s*1e9)/static_cast<double>(iters));
                if (total >= cfg.max_total_time_s) break;
            }
            JitterStats js = compute_stats(ns_per_iter);
            fmt::print("  iterations/epoch: {}  epochs: {}\n", iters, ns_per_iter.size());
            fmt::print("  ns/op: mean {:.2f}, stddev {:.2f}, min {:.2f}, max {:.2f}\n", js.mean_ns, js.stddev_ns, js.min_ns, js.max_ns);
            print_histogram(ns_per_iter, bins);
            if (failed_expect_epochs > 0) {
                double total_epochs = static_cast<double>(ns_per_iter.size() + failed_expect_epochs);
                double pct = total_epochs > 0.0 ? (100.0 * static_cast<double>(failed_expect_epochs) / total_epochs) : 0.0;
                fmt::print("  FAILED (EXPECT): {:>6} ({:>5.1f}% )\n", failed_expect_epochs, pct);
            }
            if (killed_by_assert) { fmt::print(stderr, "  ABORTED: ASSERT encountered; jitter run terminated early.\n"); return 1; }
        } catch (const std::exception& e) { fmt::print(stderr, "[ FAIL ] {} :: exception: {}\n", c.name, e.what()); return 1; } catch (...) { fmt::print(stderr, "[ FAIL ] {} :: unknown exception\n", c.name); return 1; }
    }
    return 0;
}
} // namespace

namespace {
struct Counters { std::size_t executed = 0; int failures = 0; };

// Result and reporting support (enabled via --junit=<file>)
struct RunResult {
    bool                     skipped{false};
    double                   time_s{0.0};
    std::vector<std::string> failures;
    std::vector<std::string> logs;
    std::vector<std::string> timeline;
};
struct ReportItem {
    std::string              suite;
    std::string              name;
    double                   time_s{0.0};
    bool                     skipped{false};
    std::string              skip_reason;
    std::vector<std::string> failures;
    std::vector<std::string> logs;
    std::vector<std::string> timeline;
    std::vector<std::string> tags;
    std::vector<std::string> requirements;
};
static bool                    g_record_results = false;
static std::vector<ReportItem> g_report_items;

static inline std::string xml_escape(std::string_view s) {
    std::string out;
    out.reserve(s.size());
    for (char ch : s) {
        switch (ch) {
        case '&': out += "&amp;"; break;
        case '"': out += "&quot;"; break;
        case '\'': out += "&apos;"; break;
        case '<': out += "&lt;"; break;
        case '>': out += "&gt;"; break;
        default: out.push_back(ch); break;
        }
    }
    return out;
}

RunResult execute_one(const Case& test, void* ctx, Counters& c) {
    RunResult rr;
    if (test.should_skip) {
        rr.skipped = true;
        const long long dur_ms = 0LL;
        if (g_color_output) {
            fmt::print(fmt::fg(fmt::color::yellow), "[ SKIP ]");
            if (!test.skip_reason.empty()) fmt::print(" {} :: {} ({} ms)\n", test.name, test.skip_reason, dur_ms);
            else fmt::print(" {} ({} ms)\n", test.name, dur_ms);
        } else {
            if (!test.skip_reason.empty()) fmt::print("[ SKIP ] {} :: {} ({} ms)\n", test.name, test.skip_reason, dur_ms);
            else fmt::print("[ SKIP ] {} ({} ms)\n", test.name, dur_ms);
        }
        return rr;
    }
    ++c.executed;
    auto ctxinfo = std::make_shared<gentest::detail::TestContextInfo>();
    ctxinfo->display_name = std::string(test.name);
    ctxinfo->active = true;
    gentest::detail::set_current_test(ctxinfo);
    bool threw = false;
    const auto start_tp = std::chrono::steady_clock::now();
    try {
        test.fn(ctx);
    } catch (const gentest::failure& err) {
        threw = true;
        ctxinfo->failures.push_back(std::string("FAIL() :: ") + err.what());
    } catch (const gentest::assertion&) {
        threw = true;
        // messages already recorded
    } catch (const std::exception& err) {
        threw = true;
        ctxinfo->failures.push_back(std::string("unexpected std::exception: ") + err.what());
    } catch (...) {
        threw = true;
        ctxinfo->failures.push_back("unknown exception");
    }
    ctxinfo->active = false;
    gentest::detail::set_current_test(nullptr);
    const auto end_tp = std::chrono::steady_clock::now();
    rr.time_s = std::chrono::duration<double>(end_tp - start_tp).count();
    rr.failures = ctxinfo->failures;
    rr.logs = ctxinfo->logs;
    rr.timeline = ctxinfo->event_lines;

    if (!ctxinfo->failures.empty()) {
        ++c.failures;
        const long long dur_ms = static_cast<long long>(rr.time_s * 1000.0 + 0.5);
        if (g_color_output) {
            fmt::print(stderr, fmt::fg(fmt::color::red), "[ FAIL ]");
            fmt::print(stderr, " {} :: {} issue(s) ({} ms)\n", test.name, ctxinfo->failures.size(), dur_ms);
        } else {
            fmt::print(stderr, "[ FAIL ] {} :: {} issue(s) ({} ms)\n", test.name, ctxinfo->failures.size(), dur_ms);
        }
        std::size_t failure_printed = 0;
        for (std::size_t i = 0; i < ctxinfo->event_lines.size(); ++i) {
            const char kind = (i < ctxinfo->event_kinds.size() ? ctxinfo->event_kinds[i] : 'L');
            const auto& ln = ctxinfo->event_lines[i];
            if (kind == 'F') {
                fmt::print(stderr, "{}\n", ln);
                if (g_github_annotations) {
                    std::string_view file = test.file;
                    unsigned line_no = test.line;
                    if (failure_printed < ctxinfo->failure_locations.size()) {
                        const auto& fl = ctxinfo->failure_locations[failure_printed];
                        if (!fl.file.empty() && fl.line > 0) { file = fl.file; line_no = fl.line; }
                    }
                    fmt::print("::error file={},line={},title={}::{}\n",
                               file,
                               line_no,
                               gha_escape(std::string(test.name)),
                               gha_escape(ln));
                }
                ++failure_printed;
            } else {
                fmt::print(stderr, "{}\n", ln);
            }
        }
        // Spacer after each failing test block
        fmt::print(stderr, "\n");
    } else if (!threw) {
        const long long dur_ms = static_cast<long long>(rr.time_s * 1000.0 + 0.5);
        if (g_color_output) {
            fmt::print(fmt::fg(fmt::color::green), "[ PASS ]");
            fmt::print(" {} ({} ms)\n", test.name, dur_ms);
        } else {
            fmt::print("[ PASS ] {} ({} ms)\n", test.name, dur_ms);
        }
    } else {
        // threw but no messages recorded: still a failure
        ++c.failures;
        const long long dur_ms = static_cast<long long>(rr.time_s * 1000.0 + 0.5);
        if (g_color_output) {
            fmt::print(stderr, fmt::fg(fmt::color::red), "[ FAIL ]");
            fmt::print(stderr, " {} ({} ms)\n", test.name, dur_ms);
        } else {
            fmt::print(stderr, "[ FAIL ] {} ({} ms)\n", test.name, dur_ms);
        }
        // Spacer after each failing test block
        fmt::print(stderr, "\n");
    }
    return rr;
}

inline void execute_and_record(const Case& test, void* ctx, Counters& c) {
    RunResult rr = execute_one(test, ctx, c);
    if (!g_record_results) return;
    ReportItem item;
    item.suite       = std::string(test.suite);
    item.name        = std::string(test.name);
    item.time_s      = rr.time_s;
    item.skipped     = rr.skipped;
    item.skip_reason = std::string(test.skip_reason);
    item.failures    = std::move(rr.failures);
    item.logs        = std::move(rr.logs);
    item.timeline    = std::move(rr.timeline);
    for (auto sv : test.tags) item.tags.emplace_back(sv);
    for (auto sv : test.requirements) item.requirements.emplace_back(sv);
    g_report_items.push_back(std::move(item));
}

inline void write_junit(const char* path) {
    if (!path) return;
    std::size_t total_tests = g_report_items.size();
    std::size_t total_fail = 0;
    std::size_t total_skip = 0;
    double total_time = 0.0;
    for (const auto& it : g_report_items) {
        total_fail += it.failures.empty() ? 0 : 1;
        total_skip += it.skipped ? 1 : 0;
        total_time += it.time_s;
    }
    std::ofstream f(path, std::ios::binary);
    if (!f) return;
    auto fmtd = [](double v){ std::ostringstream os; os.setf(std::ios::fixed); os.precision(6); os << v; return os.str(); };
    f << "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n";
    f << "<testsuites tests=\"" << total_tests << "\" failures=\"" << total_fail << "\" skipped=\"" << total_skip << "\" time=\"" << fmtd(total_time) << "\">\n";
    // group by suite
    std::map<std::string, std::vector<const ReportItem*>> by_suite;
    for (const auto& it : g_report_items) by_suite[it.suite].push_back(&it);
    for (const auto& [suite, vec] : by_suite) {
        std::size_t failures = 0, skipped = 0; double time = 0.0;
        for (auto* p : vec) { failures += p->failures.empty() ? 0 : 1; skipped += p->skipped ? 1 : 0; time += p->time_s; }
        f << "  <testsuite name=\"" << xml_escape(suite) << "\" tests=\"" << vec.size() << "\" failures=\"" << failures << "\" skipped=\"" << skipped << "\" time=\"" << fmtd(time) << "\">\n";
        for (auto* p : vec) {
            f << "    <testcase classname=\"" << xml_escape(suite) << "\" name=\"" << xml_escape(p->name) << "\" time=\"" << fmtd(p->time_s) << "\">\n";
            // Emit properties for tags/requirements if present
            if (!p->tags.empty() || !p->requirements.empty()) {
                f << "      <properties>\n";
                for (const auto& t : p->tags) f << "        <property name=\"tag\" value=\"" << xml_escape(t) << "\"/>\n";
                for (const auto& r : p->requirements) f << "        <property name=\"requirement\" value=\"" << xml_escape(r) << "\"/>\n";
                f << "      </properties>\n";
            }
            if (p->skipped) {
                if (!p->skip_reason.empty()) f << "      <skipped message=\"" << xml_escape(p->skip_reason) << "\"/>\n";
                else f << "      <skipped/>\n";
            } else if (!p->failures.empty()) {
                const std::string& first = p->failures.front();
                f << "      <failure message=\"" << xml_escape(first) << "\">\n<![CDATA[\n";
                if (!p->timeline.empty()) { for (const auto& ln : p->timeline) f << ln << "\n"; }
                else { for (const auto& msg : p->failures) f << msg << "\n"; }
                f << "]]></failure>\n";
            }
            f << "    </testcase>\n";
        }
        f << "  </testsuite>\n";
    }
    f << "</testsuites>\n";
}

inline void write_allure(const char* dir_path) {
    if (!dir_path) return;
    namespace fs = std::filesystem;
    std::error_code ec;
    fs::create_directories(fs::path(dir_path), ec);
    // Approximate start/stop from duration around now
    const auto now_ms = std::chrono::duration_cast<std::chrono::milliseconds>(std::chrono::system_clock::now().time_since_epoch()).count();
    std::size_t idx = 0;
    auto uuid_v4 = []() {
#ifdef GENTEST_USE_BOOST_UUID
        const auto id = boost::uuids::random_generator()();
        return boost::uuids::to_string(id);
#else
        std::array<unsigned char, 16> b{};
        std::random_device rd;
        for (auto &x : b) x = static_cast<unsigned char>(rd());
        // Set version (4) and variant (10xxxxxx)
        b[6] = static_cast<unsigned char>((b[6] & 0x0F) | 0x40);
        b[8] = static_cast<unsigned char>((b[8] & 0x3F) | 0x80);
        auto nib = [](unsigned char v) -> char {
            static const char* kHex = "0123456789abcdef";
            return kHex[v & 0x0F];
        };
        std::string s;
        s.resize(36);
        int pos = 0;
        auto emit_byte = [&](unsigned char v) {
            s[pos++] = nib((v >> 4) & 0x0F);
            s[pos++] = nib(v & 0x0F);
        };
        for (int i = 0; i < 16; ++i) {
            if (i == 4 || i == 6 || i == 8 || i == 10) s[pos++] = '-';
            emit_byte(b[i]);
        }
        return s;
#endif
    };
    auto json_escape = [](std::string_view s) {
        std::string out;
        out.reserve(s.size());
        for (char ch : s) {
            switch (ch) {
            case '\\': out += "\\\\"; break;
            case '"': out += "\\\""; break;
            case '\n': out += "\\n"; break;
            case '\r': out += "\\r"; break;
            case '\t': out += "\\t"; break;
            default: out.push_back(ch); break;
            }
        }
        return out;
    };
    for (const auto& it : g_report_items) {
        const auto duration_ms = static_cast<long long>(it.time_s * 1000.0);
        const auto start_ms = now_ms - duration_ms;
        const auto stop_ms = now_ms;
        const std::string base = "result-" + std::to_string(idx++);
        const std::string filename = (fs::path(dir_path) / (base + "-result.json")).string();
#ifdef GENTEST_USE_BOOST_JSON
        const char* status = it.skipped ? "skipped" : (it.failures.empty() ? "passed" : "failed");
        boost::json::object root;
        root["uuid"] = uuid_v4();
        root["name"] = it.name;
        root["fullName"] = it.suite + "/" + it.name;
        root["status"] = status;
        root["stage"] = "finished";
        root["start"] = static_cast<std::int64_t>(start_ms);
        root["stop"]  = static_cast<std::int64_t>(stop_ms);
        boost::json::array labels;
        labels.emplace_back(boost::json::object{{"name","suite"},{"value",it.suite}});
        root["labels"] = std::move(labels);
        if (!it.failures.empty()) {
            std::string all;
            for (const auto& m : it.failures) { all.append(m); all.push_back('\n'); }
            root["statusDetails"] = boost::json::object{{"message", it.failures.front()},{"trace", all}};
        }
        if (!it.failures.empty() && !it.logs.empty()) {
            const std::string logs_name = base + "-attachment.txt";
            const std::string logs_path = (fs::path(dir_path) / logs_name).string();
            std::ofstream lf(logs_path, std::ios::binary);
            if (lf) { for (const auto& line : it.logs) { lf << line << "\n"; } }
            boost::json::array attachments;
            attachments.emplace_back(boost::json::object{{"name","logs"},{"source",logs_name},{"type","text/plain"}});
            root["attachments"] = std::move(attachments);
        }
        std::ofstream f(filename, std::ios::binary);
        if (!f) continue;
        f << boost::json::serialize(root) << '\n';
#else
        std::ofstream f(filename, std::ios::binary);
        if (!f) continue;
        const char* status = it.skipped ? "skipped" : (it.failures.empty() ? "passed" : "failed");
        std::string first_msg = it.failures.empty() ? std::string() : it.failures.front();
        // Minimal Allure 2 result JSON
        f << "{\n";
        const std::string uuid = uuid_v4();
        f << "  \"uuid\": \"" << json_escape(uuid) << "\",\n";
        f << "  \"name\": \"" << json_escape(it.name) << "\",\n";
        f << "  \"fullName\": \"" << json_escape(it.suite + "/" + it.name) << "\",\n";
        f << "  \"status\": \"" << status << "\",\n";
        f << "  \"stage\": \"finished\",\n";
        // Allure 2 uses top-level start/stop; time object is optional and ignored by readers.
        f << "  \"start\": " << start_ms << ",\n";
        f << "  \"stop\": " << stop_ms << ",\n";
        f << "  \"labels\": [ { \"name\": \"suite\", \"value\": \"" << json_escape(it.suite) << "\" } ]";
        bool wrote_details = false;
        if (!it.failures.empty()) {
            f << ",\n  \"statusDetails\": { \"message\": \"" << json_escape(first_msg) << "\", \"trace\": \"";
            std::string all;
            for (const auto& m : it.failures) { all.append(m); all.push_back('\n'); }
            f << json_escape(all) << "\" }";
            wrote_details = true;
        }
        // Attach logs as an attachment when failing and logs exist
        if (!it.failures.empty() && !it.logs.empty()) {
            const std::string logs_name = base + "-attachment.txt";
            const std::string logs_path = (fs::path(dir_path) / logs_name).string();
            std::ofstream lf(logs_path, std::ios::binary);
            if (lf) { for (const auto& line : it.logs) { lf << line << "\n"; } }
            f << (wrote_details ? ",\n" : ",\n")
              << "  \"attachments\": [ { \"name\": \"logs\", \"source\": \"" << json_escape(logs_name) << "\", \"type\": \"text/plain\" } ]\n";
        } else {
            f << "\n";
        }
        f << "}\n";
#endif
    }
}
} // namespace

// Group runners for fixture-based tests.
// Generated per-fixture group; invoked after free tests.
{{GROUP_RUNNERS}}

auto {{ENTRY_FUNCTION}}(std::span<const char*> args) -> int {
    g_color_output = use_color(args);
    g_report_items.clear();
    g_github_annotations = wants_github_annotations(args) || env_github_actions();
    if (wants_help(args)) {
        fmt::print("gentest v{{VERSION}}\n");
        fmt::print("Usage: [options]\n");
        fmt::print("  --help                Show this help\n");
        fmt::print("  --list-tests          List test names (one per line)\n");
        fmt::print("  --list                List tests with metadata\n");
        fmt::print("  --run-test=<name>     Run a single test by exact name\n");
        fmt::print("  --filter=<pattern>    Run tests matching wildcard pattern (*, ?)\n");
        fmt::print("  --no-color            Disable colorized output (or set NO_COLOR/GENTEST_NO_COLOR)\n");
        fmt::print("  --github-annotations  Emit GitHub Actions annotations (::error ...) on failures\n");
        fmt::print("  --junit=<file>        Write JUnit XML report to file\n");
        fmt::print("  --allure-dir=<dir>    Write Allure result JSON files into directory\n");
        fmt::print("  --fail-fast           Stop after the first failing test\n");
        fmt::print("  --repeat=N            Repeat selected tests N times (default 1)\n");
        fmt::print("  --shuffle-fixtures    Shuffle order within each fixture group\n");
        fmt::print("  --seed N              RNG seed used with --shuffle-fixtures\n");
        fmt::print("\n");
        fmt::print("Benchmark options:\n");
        fmt::print("  --list-benches        List benchmark names (one per line)\n");
        fmt::print("  --run-bench=<name>    Run a single benchmark by exact name\n");
        fmt::print("  --bench-filter=<pat>  Run benchmarks matching wildcard pattern (*, ?)\n");
        fmt::print("  --bench-min-epoch-time-s=SECS   Minimum epoch duration (default 0.01)\n");
        fmt::print("  --bench-epochs=N      Number of measured epochs (default 12)\n");
        fmt::print("  --bench-warmup=N      Warmup epochs (default 1)\n");
        fmt::print("  --bench-max-total-time-s=SECS   Max total time per bench (default 1.0)\n");
        fmt::print("Jitter options:\n");
        fmt::print("  --list-jitters        List jitter benchmark names (one per line)\n");
        fmt::print("  --run-jitter=<name>   Run a single jitter benchmark by exact name\n");
        fmt::print("  --jitter-filter=<pat> Run jitter benchmarks matching wildcard pattern (*, ?)\n");
        fmt::print("  --jitter-bins=N       Histogram bins (default 10)\n");
        return 0;
    }
    if (wants_list_tests(args)) {
        for (const auto& t : kCases) if (!t.is_benchmark) fmt::print("{}\n", t.name);
        return 0;
    }
    if (wants_list(args)) {
        for (const auto& test : kCases) {
            if (test.is_benchmark) continue;
            std::string sections;
            if (!test.tags.empty() || !test.requirements.empty() || test.should_skip) {
                sections.push_back(' ');
                sections.push_back('[');
                bool first = true;
                if (!test.tags.empty()) {
                    sections.append("tags=");
                    sections.append(join_span(test.tags, ','));
                    first = false;
                }
                if (!test.requirements.empty()) {
                    if (!first) sections.push_back(';');
                    sections.append("requires=");
                    sections.append(join_span(test.requirements, ','));
                    first = false;
                }
                if (test.should_skip) {
                    if (!first) sections.push_back(';');
                    sections.append("skip");
                    if (!test.skip_reason.empty()) { sections.push_back('='); sections.append(test.skip_reason); }
                }
                sections.push_back(']');
            }
            fmt::print("{}{} ({}:{})\n", test.name, sections, test.file, test.line);
        }
        return 0;
    }
    // Benchmark mode: handles --list-benches / --run-bench / --bench-filter
    {
        int bench_rc = handle_bench_cli(args);
        if (bench_rc >= 0) return bench_rc;
    }
    // Jitter benchmark mode
    {
        int jit_rc = handle_jitter_cli(args);
        if (jit_rc >= 0) return jit_rc;
    }
    Counters counters;
    const char* junit_path = get_arg_value(args, "--junit=");
    const char* allure_dir = get_arg_value(args, "--allure-dir=");
    g_record_results = (junit_path != nullptr) || (allure_dir != nullptr);

    // Selection support: --run-test / --filter
    const char* run_exact = get_arg_value(args, "--run-test=");
    const char* filter_pat = get_arg_value(args, "--filter=");
    if (run_exact || filter_pat) {
        std::vector<std::size_t> sel;
        if (run_exact) {
            for (std::size_t i = 0; i < kCases.size(); ++i) if (!kCases[i].is_benchmark && kCases[i].name == run_exact) { sel.push_back(i); break; }
            if (sel.empty()) { fmt::print(stderr, "Test not found: {}\n", run_exact); return 1; }
        } else {
            for (std::size_t i = 0; i < kCases.size(); ++i) if (!kCases[i].is_benchmark && wildcard_match(kCases[i].name, filter_pat)) sel.push_back(i);
            if (sel.empty()) { fmt::print("Executed 0 test(s).\n"); return 0; }
        }
        const bool        fail_fast = wants_fail_fast(args);
        const std::size_t repeat_n  = parse_repeat(args);
        for (std::size_t iter = 0; iter < repeat_n; ++iter) {
            // Free tests
            for (auto i : sel) {
                const auto& t = kCases[i];
                if (!t.fixture.empty()) continue;
                execute_and_record(t, nullptr, counters);
                if (fail_fast && counters.failures > 0) goto done_selection;
            }
            // Fixture tests honour lifetime semantics during selection as well.
            const bool         shuffle = wants_shuffle(args);
            const std::uint64_t seed    = parse_seed(args);
            if (shuffle) fmt::print("Shuffle seed: {}\n", seed);
            // Group by fixture name
            std::vector<std::pair<std::string_view, std::vector<std::size_t>>> groups;
            for (auto i : sel) { const auto& t = kCases[i]; if (t.fixture.empty()) continue; auto it = std::find_if(groups.begin(), groups.end(), [&](auto& g){return g.first==t.fixture;}); if (it==groups.end()) groups.push_back({t.fixture,{i}}); else it->second.push_back(i); }
            for (std::size_t gid = 0; gid < groups.size(); ++gid) {
                auto order = groups[gid].second;
                if (shuffle && order.size() > 1) { std::mt19937_64 rng(seed ? (seed + gid) : std::mt19937_64::result_type(std::random_device{}())); std::shuffle(order.begin(), order.end(), rng); }
                for (auto i : order) {
                    const auto& test = kCases[i];
                    void* ctx = nullptr;
                    switch (test.fixture_lifetime) {
                    case FixtureLifetime::MemberSuite:
                    case FixtureLifetime::MemberGlobal:
                        if (test.acquire_fixture) {
                            ctx = test.acquire_fixture(test.suite);
                        }
                        break;
                    case FixtureLifetime::MemberEphemeral:
                    case FixtureLifetime::None:
                    default:
                        ctx = nullptr;
                        break;
                    }
                    execute_and_record(test, ctx, counters);
                    if (fail_fast && counters.failures > 0) goto done_selection;
                }
            }
        }
        done_selection:
        if (counters.failures == 0) {
            fmt::print("Executed {} test(s).\n", counters.executed);
        } else {
            fmt::print(stderr, "Executed {} test(s) with {} failure(s).\n", counters.executed, counters.failures);
        }
        if (g_record_results) { if (junit_path) write_junit(junit_path); if (allure_dir) write_allure(allure_dir); }
        return counters.failures == 0 ? 0 : 1;
    }

    // Default path: run all tests with built-in grouping
    {
        const bool        fail_fast = wants_fail_fast(args);
        const std::size_t repeat_n  = parse_repeat(args);
        for (std::size_t iter = 0; iter < repeat_n; ++iter) {
            for (const auto& t : kCases) { if (t.is_benchmark) continue; if (!t.fixture.empty()) continue; execute_and_record(t, nullptr, counters); if (fail_fast && counters.failures > 0) goto done_all; }
            const bool         shuffle = wants_shuffle(args);
            const std::uint64_t seed    = parse_seed(args);
            if (shuffle) fmt::print("Shuffle seed: {}\n", seed);
            {{RUN_GROUPS}}
            if (fail_fast && counters.failures > 0) goto done_all;
        }
    }
    done_all:
    if (counters.failures == 0) {
        fmt::print("Executed {} test(s).\n", counters.executed);
    } else {
        fmt::print(stderr, "Executed {} test(s) with {} failure(s).\n", counters.executed, counters.failures);
    }
    if (g_record_results) { if (junit_path) write_junit(junit_path); if (allure_dir) write_allure(allure_dir); }
    return counters.failures == 0 ? 0 : 1;
}

auto {{ENTRY_FUNCTION}}(int argc, char** argv) -> int {
    std::vector<const char*> args;
    args.reserve(static_cast<std::size_t>(argc));
    for (int i = 0; i < argc; ++i) {
        args.push_back(argv[i]);
    }
    return {{ENTRY_FUNCTION}}(std::span<const char*>{args.data(), args.size()});
}
)CPP";

inline constexpr std::string_view wrapper_free = R"FMT(static void {w}(void* ctx_) {{
    (void)ctx_;
    {invoke}
}}

)FMT";

inline constexpr std::string_view wrapper_free_fixtures = R"FMT(static void {w}(void* ctx_) {{
    (void)ctx_;
{decls}{setup}    {invoke}
{teardown}}}

)FMT";

inline constexpr std::string_view wrapper_ephemeral = R"FMT(static void {w}(void* ctx_) {{
    (void)ctx_;
    {fixture} fx_;
    gentest_maybe_setup(fx_);
    {invoke}
    gentest_maybe_teardown(fx_);
}}

)FMT";

inline constexpr std::string_view wrapper_stateful = R"FMT(static void {w}(void* ctx_) {{
    auto* fx_ = static_cast<{fixture}*>(ctx_);
    gentest_maybe_setup(*fx_);
    {invoke}
    gentest_maybe_teardown(*fx_);
}}

)FMT";

inline constexpr std::string_view case_entry = R"FMT(    Case{{
        .name = "{name}",
        .fn = &{wrapper},
        .file = "{file}",
        .line = {line},
        .is_benchmark = {is_bench},
        .is_jitter = {is_jitter},
        .tags = std::span{{{tags}}},
        .requirements = std::span{{{reqs}}},
        .skip_reason = {skip_reason},
        .should_skip = {should_skip},
        .fixture = {fixture},
        .fixture_lifetime = {lifetime},
        .suite = {suite},
        .acquire_fixture = {acquire}
    }},

)FMT";

inline constexpr std::string_view group_runner_ephemeral =
    R"FMT(static void gentest_run_group_{gid}(bool shuffle_, std::uint64_t seed_, Counters& counters_) {{
    using Fixture = {fixture};
    const std::array<std::size_t, {count}> idxs_ = {{ {idxs} }};
    std::vector<std::size_t> order_(idxs_.begin(), idxs_.end());
    if (shuffle_ && order_.size() > 1) {{ std::mt19937_64 rng_(seed_ ? (seed_ + {gid}) : std::mt19937_64::result_type(std::random_device{{}}())); std::shuffle(order_.begin(), order_.end(), rng_); }}
    for (auto i_ : order_) {{ execute_and_record(kCases[i_], nullptr, counters_); }}
}}

)FMT";

inline constexpr std::string_view group_runner_suite = R"FMT(static void* gentest_access_fixture_{gid}(std::string_view suite_) {{
    using Fixture = {fixture};
    struct Entry {{ std::string_view key; std::unique_ptr<Fixture> instance; }};
    static std::vector<Entry> fixtures_;
    for (auto& entry : fixtures_) {{ if (entry.key == suite_) return entry.instance.get(); }}
    fixtures_.push_back(Entry{{ .key = suite_, .instance = std::make_unique<Fixture>() }});
    return fixtures_.back().instance.get();
}}

static void gentest_run_group_{gid}(bool shuffle_, std::uint64_t seed_, Counters& counters_) {{
    using Fixture = {fixture};
    const std::array<std::size_t, {count}> idxs_ = {{ {idxs} }};
    std::vector<std::size_t> order_(idxs_.begin(), idxs_.end());
    if (shuffle_ && order_.size() > 1) {{ std::mt19937_64 rng_(seed_ ? (seed_ + {gid}) : std::mt19937_64::result_type(std::random_device{{}}())); std::shuffle(order_.begin(), order_.end(), rng_); }}
    for (auto i_ : order_) {{
        auto* fx_ = static_cast<Fixture*>(gentest_access_fixture_{gid}(kCases[i_].suite));
        execute_and_record(kCases[i_], fx_, counters_);
    }}
}}

)FMT";

inline constexpr std::string_view group_runner_global = R"FMT(static void* gentest_access_fixture_{gid}(std::string_view) {{
    using Fixture = {fixture};
    static Fixture fx_;
    return &fx_;
}}

static void gentest_run_group_{gid}(bool shuffle_, std::uint64_t seed_, Counters& counters_) {{
    using Fixture = {fixture};
    const std::array<std::size_t, {count}> idxs_ = {{ {idxs} }};
    std::vector<std::size_t> order_(idxs_.begin(), idxs_.end());
    if (shuffle_ && order_.size() > 1) {{ std::mt19937_64 rng_(seed_ ? (seed_ + {gid}) : std::mt19937_64::result_type(std::random_device{{}}())); std::shuffle(order_.begin(), order_.end(), rng_); }}
    auto* fx_ = static_cast<Fixture*>(gentest_access_fixture_{gid}(std::string_view{{}}));
    for (auto i_ : order_) {{ execute_and_record(kCases[i_], fx_, counters_); }}
}}

)FMT";

inline constexpr std::string_view array_decl_empty = R"FMT(constexpr std::array<std::string_view, 0> {name}{{}};

)FMT";

inline constexpr std::string_view array_decl_nonempty = R"FMT(constexpr std::array<std::string_view, {count}> {name} = {{
{body}
}};

)FMT";

inline constexpr std::string_view forward_decl_line = R"FMT(void {name}();

)FMT";

inline constexpr std::string_view forward_decl_ns = R"FMT(namespace {scope} {{
{lines}}} // namespace {scope}

)FMT";

} // namespace gentest::codegen::tpl
